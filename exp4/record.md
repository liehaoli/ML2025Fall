我们对代码进行了三次重要的迭代改进，以下是之前代码中存在的三个核心问题总结： 1. 方法论问题：缺乏验证集 (Blind Flying) • 问题描述：原代码只计算和打印 Training Loss。  • 后果：  • 无法判断收敛：Training Loss 永远是下降的（甚至趋近于0），但你无法知道模型是否“死记硬背”了图片（过拟合）。  • 盲目自信：你可能认为模型越来越好，但实际上它在未知数据上的生成能力可能已经变差了。  • 修复：引入 CIFAR-10 测试集作为验证集，增加了 evaluate 函数，通过 Val Loss 来真实评估模型能力。   2. 逻辑漏洞：模型保存策略不安全 (Unsafe Checkpointing) • 问题描述：  1. 保存判断标准是 Training Loss（容易保存过拟合的模型）。  2. 断点续训时，best_loss 被重置为无穷大 (inf)。  • 后果 (灾难性覆盖)：如果你有一个训练得很好的模型（Loss=0.02），中断后重启训练，新一轮的 Loss 是 0.05。因为 0.05 < inf，代码会立即判定这是“新纪录”，并用 0.05 的差模型覆盖掉硬盘里 0.02 的好模型。  • 修复：  • 改为根据 Val Loss 保存模型。  • 启动时先读取硬盘上已有的 best_model 的 Loss 值，确保只有真的超越历史最佳时才覆盖。   3. 更换模型架构，从简单的Unet实现，转向和DDPM论文里的实现对齐。把网络替换为DDPM论文里的架构（在Unet基础上增加了残差块和注意力机制）4.调参技巧，引入余弦退火学习率调度。


实验结果对比：
助教给的最优权重：
FID Score: 224.8789, Inception Score: 2.6666 ± 0.8039

我们代码训练出来的最优权重：
FID Score: 204.1046，Inception Score: 2.9956 ± 0.8238